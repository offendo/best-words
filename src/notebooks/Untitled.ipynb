{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:21.738007Z",
     "start_time": "2020-12-07T21:22:21.609400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:25.475832Z",
     "start_time": "2020-12-07T21:22:22.120072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import data\\nfrom collections import Counter\\nimport retrieval as ret\\nimport lstm\\nfrom trainer import Trainer\\nimport pandas as pd\\nimport numpy as np\\nimport torch\\nimport mlp\\nfrom torch.utils.data import DataLoader\\nimport torch.optim as optim\\nfrom sklearn.model_selection import train_test_split\\n\\n# torch.multiprocessing.set_start_method(\\\"spawn\\\", force=True)  # multiprocessing\\n# from sentence_transformers import SentenceTransformer, util\\n# from transformers import AutoTokenizer, AutoModelForMaskedLM\\n# import simpletransformers\\n# import spacy\\n# import pytextrank\";\n",
       "                var nbb_formatted_code = \"import data\\nfrom collections import Counter\\nimport retrieval as ret\\nimport lstm\\nfrom trainer import Trainer\\nimport pandas as pd\\nimport numpy as np\\nimport torch\\nimport mlp\\nfrom torch.utils.data import DataLoader\\nimport torch.optim as optim\\nfrom sklearn.model_selection import train_test_split\\n\\n# torch.multiprocessing.set_start_method(\\\"spawn\\\", force=True)  # multiprocessing\\n# from sentence_transformers import SentenceTransformer, util\\n# from transformers import AutoTokenizer, AutoModelForMaskedLM\\n# import simpletransformers\\n# import spacy\\n# import pytextrank\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import data\n",
    "from collections import Counter\n",
    "import retrieval as ret\n",
    "import lstm\n",
    "from trainer import Trainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import mlp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# torch.multiprocessing.set_start_method(\"spawn\", force=True)  # multiprocessing\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "# import simpletransformers\n",
    "# import spacy\n",
    "# import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:25.507899Z",
     "start_time": "2020-12-07T21:22:25.479479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# outdir = \\\"../data/clean/\\\"\\n# for file in tqdm(index.keys()):\\n#     wiki = data.get_wiki(file)\\n#     lines = wiki[\\\"lines\\\"].apply(lambda l: \\\"<SPLIT>\\\".join(data.clean_article(l)))\\n#     wiki[\\\"text\\\"] = lines\\n#     wiki = wiki.drop(\\\"lines\\\", axis=1).reset_index()\\n#     new_file = outdir + file.split(\\\"/\\\")[-1]\\n#     wiki.to_json(new_file, orient=\\\"records\\\", lines=True)\";\n",
       "                var nbb_formatted_code = \"# outdir = \\\"../data/clean/\\\"\\n# for file in tqdm(index.keys()):\\n#     wiki = data.get_wiki(file)\\n#     lines = wiki[\\\"lines\\\"].apply(lambda l: \\\"<SPLIT>\\\".join(data.clean_article(l)))\\n#     wiki[\\\"text\\\"] = lines\\n#     wiki = wiki.drop(\\\"lines\\\", axis=1).reset_index()\\n#     new_file = outdir + file.split(\\\"/\\\")[-1]\\n#     wiki.to_json(new_file, orient=\\\"records\\\", lines=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# outdir = \"../data/clean/\"\n",
    "# for file in tqdm(index.keys()):\n",
    "#     wiki = data.get_wiki(file)\n",
    "#     lines = wiki[\"lines\"].apply(lambda l: \"<SPLIT>\".join(data.clean_article(l)))\n",
    "#     wiki[\"text\"] = lines\n",
    "#     wiki = wiki.drop(\"lines\", axis=1).reset_index()\n",
    "#     new_file = outdir + file.split(\"/\")[-1]\n",
    "#     wiki.to_json(new_file, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:29.324541Z",
     "start_time": "2020-12-07T21:22:25.509807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"train = data.get_train(\\\"../data/train.jsonl\\\")\\ntrain = train.explode(\\\"evidence\\\").reset_index()\\ntrain, test = train_test_split(train)\";\n",
       "                var nbb_formatted_code = \"train = data.get_train(\\\"../data/train.jsonl\\\")\\ntrain = train.explode(\\\"evidence\\\").reset_index()\\ntrain, test = train_test_split(train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = data.get_train(\"../data/train.jsonl\")\n",
    "train = train.explode(\"evidence\").reset_index()\n",
    "train, test = train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:31.604145Z",
     "start_time": "2020-12-07T21:22:29.327773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"embedder = ret.SentEmbed(\\\"distilroberta-base-msmarco-v2\\\")\";\n",
       "                var nbb_formatted_code = \"embedder = ret.SentEmbed(\\\"distilroberta-base-msmarco-v2\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedder = ret.SentEmbed(\"distilroberta-base-msmarco-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:31.659440Z",
     "start_time": "2020-12-07T21:22:31.605814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"train_dataset = data.SentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\ntest_dataset = data.SentenceDataset(test, embedder, \\\"../data/wiki.db\\\", 4)\";\n",
       "                var nbb_formatted_code = \"train_dataset = data.SentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\ntest_dataset = data.SentenceDataset(test, embedder, \\\"../data/wiki.db\\\", 4)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = data.SentenceDataset(train, embedder, \"../data/wiki.db\", 4)\n",
    "test_dataset = data.SentenceDataset(test, embedder, \"../data/wiki.db\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:31.798394Z",
     "start_time": "2020-12-07T21:22:31.661223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"train_loader = DataLoader(\\n    train_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=train_dataset.collate,\\n    num_workers=0,\\n)\\ntest_loader = DataLoader(\\n    test_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_formatted_code = \"train_loader = DataLoader(\\n    train_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=train_dataset.collate,\\n    num_workers=0,\\n)\\ntest_loader = DataLoader(\\n    test_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.collate,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    collate_fn=test_dataset.collate,\n",
    "    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:36.315510Z",
     "start_time": "2020-12-07T21:22:36.265173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIM = 100\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nN_LAYERS = 2\\nDROPOUT = 1e-1\\nBIDIRECTIONAL = True\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-3\\nLR_DECAY = 1e-3\";\n",
       "                var nbb_formatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIM = 100\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nN_LAYERS = 2\\nDROPOUT = 1e-1\\nBIDIRECTIONAL = True\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-3\\nLR_DECAY = 1e-3\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Model params\n",
    "EMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\n",
    "HIDDEN_DIM = 100\n",
    "OUTPUT_DIM = 3  # refute, not enough info, support\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 1e-1\n",
    "BIDIRECTIONAL = True\n",
    "# Loss fn params\n",
    "WEIGHT_DECAY = 1e-4\n",
    "N_EPOCHS = 3\n",
    "LR = 1e-3\n",
    "LR_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:42.160682Z",
     "start_time": "2020-12-07T21:22:36.868349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"model = lstm.LSTMClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dim=HIDDEN_DIM,\\n    output_dim=OUTPUT_DIM,\\n    n_layers=N_LAYERS,\\n    dropout=DROPOUT,\\n    bidirectional=BIDIRECTIONAL,\\n    pad_idx=train_dataset.input_pad_idx,\\n)\\nmodel.to(device)\\nstate_dict = torch.load(\\\"../models/bilstm-nli-model-2.pt\\\")\\nmodel.load_state_dict(state_dict)\\noptimizer = optim.Adam(model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx,\\n    reduction=\\\"sum\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"model = lstm.LSTMClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dim=HIDDEN_DIM,\\n    output_dim=OUTPUT_DIM,\\n    n_layers=N_LAYERS,\\n    dropout=DROPOUT,\\n    bidirectional=BIDIRECTIONAL,\\n    pad_idx=train_dataset.input_pad_idx,\\n)\\nmodel.to(device)\\nstate_dict = torch.load(\\\"../models/bilstm-nli-model-2.pt\\\")\\nmodel.load_state_dict(state_dict)\\noptimizer = optim.Adam(model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx,\\n    reduction=\\\"sum\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lstm.LSTMClassifier(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    pad_idx=train_dataset.input_pad_idx,\n",
    ")\n",
    "model.to(device)\n",
    "state_dict = torch.load(\"../models/bilstm-nli-model-2.pt\")\n",
    "model.load_state_dict(state_dict)\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(\n",
    "    ignore_index=train_dataset.output_pad_idx,\n",
    "    reduction=\"sum\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:42.208006Z",
     "start_time": "2020-12-07T21:22:42.163669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"trainer = Trainer(model, optimizer, loss_fn, device, log_every_n=1)\\nlabels = {0: \\\"REFUTES\\\", 1: \\\"NOT ENOUGH INFO\\\", 2: \\\"SUPPORT\\\"}\";\n",
       "                var nbb_formatted_code = \"trainer = Trainer(model, optimizer, loss_fn, device, log_every_n=1)\\nlabels = {0: \\\"REFUTES\\\", 1: \\\"NOT ENOUGH INFO\\\", 2: \\\"SUPPORT\\\"}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, loss_fn, device, log_every_n=1)\n",
    "labels = {0: \"REFUTES\", 1: \"NOT ENOUGH INFO\", 2: \"SUPPORT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T17:58:52.292042Z",
     "start_time": "2020-12-07T17:58:52.249524Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 151;\n",
       "                var nbb_unformatted_code = \"# trainer.fit(\\n#     train_loader=train_loader,\\n#     valid_loader=test_loader,\\n#     labels=labels,\\n#     n_epochs=N_EPOCHS,\\n# )\";\n",
       "                var nbb_formatted_code = \"# trainer.fit(\\n#     train_loader=train_loader,\\n#     valid_loader=test_loader,\\n#     labels=labels,\\n#     n_epochs=N_EPOCHS,\\n# )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainer.fit(\n",
    "#     train_loader=train_loader,\n",
    "#     valid_loader=test_loader,\n",
    "#     labels=labels,\n",
    "#     n_epochs=N_EPOCHS,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T17:58:52.833082Z",
     "start_time": "2020-12-07T17:58:52.802263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 152;\n",
       "                var nbb_unformatted_code = \"# torch.save(model.state_dict(), \\\"../models/bilstm-nli-model-3.pt\\\")\";\n",
       "                var nbb_formatted_code = \"# torch.save(model.state_dict(), \\\"../models/bilstm-nli-model-3.pt\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"../models/bilstm-nli-model-3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:42.873737Z",
     "start_time": "2020-12-07T21:22:42.809210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Small test dataset/loader\\nsmall_test_dataset = data.SentenceDataset(test[:1000], embedder, \\\"../data/wiki.db\\\", 4)\\nsmall_test_loader = DataLoader(\\n    small_test_dataset,\\n    batch_size=4,\\n    shuffle=False,\\n    collate_fn=test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_formatted_code = \"# Small test dataset/loader\\nsmall_test_dataset = data.SentenceDataset(test[:1000], embedder, \\\"../data/wiki.db\\\", 4)\\nsmall_test_loader = DataLoader(\\n    small_test_dataset,\\n    batch_size=4,\\n    shuffle=False,\\n    collate_fn=test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Small test dataset/loader\n",
    "small_test_dataset = data.SentenceDataset(test[:1000], embedder, \"../data/wiki.db\", 4)\n",
    "small_test_loader = DataLoader(\n",
    "    small_test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=test_dataset.collate,\n",
    "    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:24:06.497117Z",
     "start_time": "2020-12-07T21:22:43.849478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [01:22<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 11.962440080420919\n",
      "Classification report after epoch:\n",
      "Evidence accuracy: 0.320139697322468\n",
      "Number correct: 275 out of 859\n",
      "Fever score: 0.36321303841676367\n",
      "Number right: 312 out of 859\n",
      "Label accuracy: 0.6507566938300349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"loss, running_loss = trainer.evaluate(small_test_loader, labels)\";\n",
       "                var nbb_formatted_code = \"loss, running_loss = trainer.evaluate(small_test_loader, labels)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, running_loss = trainer.evaluate(small_test_loader, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:56:27.464560Z",
     "start_time": "2020-12-07T21:56:27.427836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"claim = \\\"George Lucas and Mark Hamill have worked together\\\"\\na = \\\"Luke Skywalker is a protagonist in Star Wars\\\"\\nb = \\\"George Lucas directs Star Wars\\\"\\nc = \\\"Mark Hamill plays Luke Skywalker\\\"\\nd = b + \\\" and \\\" + c\\ne = \\\"Mark Hamill and George Lucas were part of Star Wars\\\"\";\n",
       "                var nbb_formatted_code = \"claim = \\\"George Lucas and Mark Hamill have worked together\\\"\\na = \\\"Luke Skywalker is a protagonist in Star Wars\\\"\\nb = \\\"George Lucas directs Star Wars\\\"\\nc = \\\"Mark Hamill plays Luke Skywalker\\\"\\nd = b + \\\" and \\\" + c\\ne = \\\"Mark Hamill and George Lucas were part of Star Wars\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "claim = \"George Lucas and Mark Hamill have worked together\"\n",
    "a = \"Luke Skywalker is a protagonist in Star Wars\"\n",
    "b = \"George Lucas directs Star Wars\"\n",
    "c = \"Mark Hamill plays Luke Skywalker\"\n",
    "d = b + \" and \" + c\n",
    "e = \"Mark Hamill and George Lucas were part of Star Wars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:56:29.485180Z",
     "start_time": "2020-12-07T21:56:29.423480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1483, 0.3690, 0.4195, 0.4155, 0.7016]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"embedder.compare(claim, [a, b, c, d, e])\";\n",
       "                var nbb_formatted_code = \"embedder.compare(claim, [a, b, c, d, e])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedder.compare(claim, [a, b, c, d, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:48.208576Z",
     "start_time": "2020-12-07T16:04:47.815292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 117;\n",
       "                var nbb_unformatted_code = \"mlp_train_dataset = data.MLPSentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\nmlp_test_dataset = data.MLPSentenceDataset(test[:100], embedder, \\\"../data/wiki.db\\\", 4)\\n\\nmlp_train_loader = DataLoader(\\n    mlp_train_dataset,\\n    batch_size=512,\\n    shuffle=True,\\n    collate_fn=mlp_train_dataset.collate,\\n    num_workers=0,\\n)\\nmlp_test_loader = DataLoader(\\n    mlp_test_dataset,\\n    batch_size=20,\\n    shuffle=False,\\n    collate_fn=mlp_test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_formatted_code = \"mlp_train_dataset = data.MLPSentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\nmlp_test_dataset = data.MLPSentenceDataset(test[:100], embedder, \\\"../data/wiki.db\\\", 4)\\n\\nmlp_train_loader = DataLoader(\\n    mlp_train_dataset,\\n    batch_size=512,\\n    shuffle=True,\\n    collate_fn=mlp_train_dataset.collate,\\n    num_workers=0,\\n)\\nmlp_test_loader = DataLoader(\\n    mlp_test_dataset,\\n    batch_size=20,\\n    shuffle=False,\\n    collate_fn=mlp_test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_train_dataset = data.MLPSentenceDataset(train, embedder, \"../data/wiki.db\", 4)\n",
    "mlp_test_dataset = data.MLPSentenceDataset(test[:100], embedder, \"../data/wiki.db\", 4)\n",
    "\n",
    "mlp_train_loader = DataLoader(\n",
    "    mlp_train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    collate_fn=mlp_train_dataset.collate,\n",
    "    num_workers=0,\n",
    ")\n",
    "mlp_test_loader = DataLoader(\n",
    "    mlp_test_dataset,\n",
    "    batch_size=20,\n",
    "    shuffle=False,\n",
    "    collate_fn=mlp_test_dataset.collate,\n",
    "    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:50.501493Z",
     "start_time": "2020-12-07T16:04:48.245013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 118;\n",
       "                var nbb_unformatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIMS = [300, 50]\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nDROPOUT = 1e-1\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-2\\nLR_DECAY = 1e-3\\n# Class weights\\nlens = train[\\\"evidence\\\"].apply(len)\\nlabs = train[\\\"label\\\"].apply(lambda x: [x])\\n# Assuming we have 15 selected sentences per claim (and 100% recall)\\n# We would have X of them be the correct label (number of evidence in the evidence column)\\n# and 15 - X would be NEI. This is a way to adjust the class weights to account for that\\nnei = train[\\\"label\\\"].apply(lambda x: [1])\\nfrequencies = ((15 - lens) * nei + (labs * lens)).explode().value_counts().sort_index()\\nclass_weights = 1 + torch.softmax(-torch.log2(torch.Tensor(frequencies)), dim=0).to(\\n    device\\n)\";\n",
       "                var nbb_formatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIMS = [300, 50]\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nDROPOUT = 1e-1\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-2\\nLR_DECAY = 1e-3\\n# Class weights\\nlens = train[\\\"evidence\\\"].apply(len)\\nlabs = train[\\\"label\\\"].apply(lambda x: [x])\\n# Assuming we have 15 selected sentences per claim (and 100% recall)\\n# We would have X of them be the correct label (number of evidence in the evidence column)\\n# and 15 - X would be NEI. This is a way to adjust the class weights to account for that\\nnei = train[\\\"label\\\"].apply(lambda x: [1])\\nfrequencies = ((15 - lens) * nei + (labs * lens)).explode().value_counts().sort_index()\\nclass_weights = 1 + torch.softmax(-torch.log2(torch.Tensor(frequencies)), dim=0).to(\\n    device\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Model params\n",
    "EMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\n",
    "HIDDEN_DIMS = [300, 50]\n",
    "OUTPUT_DIM = 3  # refute, not enough info, support\n",
    "DROPOUT = 1e-1\n",
    "# Loss fn params\n",
    "WEIGHT_DECAY = 1e-4\n",
    "N_EPOCHS = 3\n",
    "LR = 1e-2\n",
    "LR_DECAY = 1e-3\n",
    "# Class weights\n",
    "lens = train[\"evidence\"].apply(len)\n",
    "labs = train[\"label\"].apply(lambda x: [x])\n",
    "# Assuming we have 15 selected sentences per claim (and 100% recall)\n",
    "# We would have X of them be the correct label (number of evidence in the evidence column)\n",
    "# and 15 - X would be NEI. This is a way to adjust the class weights to account for that\n",
    "nei = train[\"label\"].apply(lambda x: [1])\n",
    "frequencies = ((15 - lens) * nei + (labs * lens)).explode().value_counts().sort_index()\n",
    "class_weights = 1 + torch.softmax(-torch.log2(torch.Tensor(frequencies)), dim=0).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:50.544590Z",
     "start_time": "2020-12-07T16:04:50.502970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (fc1): Linear(in_features=1537, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 119;\n",
       "                var nbb_unformatted_code = \"mlp_model = mlp.MLPClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dims=HIDDEN_DIMS,\\n    output_dim=OUTPUT_DIM,\\n    dropout=DROPOUT,\\n    pad_idx=mlp_train_dataset.input_pad_idx,\\n)\\nmlp_model.to(device)\";\n",
       "                var nbb_formatted_code = \"mlp_model = mlp.MLPClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dims=HIDDEN_DIMS,\\n    output_dim=OUTPUT_DIM,\\n    dropout=DROPOUT,\\n    pad_idx=mlp_train_dataset.input_pad_idx,\\n)\\nmlp_model.to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_model = mlp.MLPClassifier(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dims=HIDDEN_DIMS,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=mlp_train_dataset.input_pad_idx,\n",
    ")\n",
    "mlp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:50.605099Z",
     "start_time": "2020-12-07T16:04:50.547357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 120;\n",
       "                var nbb_unformatted_code = \"optimizer = optim.Adam(mlp_model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx, reduction=\\\"sum\\\", weight=class_weights\\n)\";\n",
       "                var nbb_formatted_code = \"optimizer = optim.Adam(mlp_model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx, reduction=\\\"sum\\\", weight=class_weights\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optim.Adam(mlp_model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(\n",
    "    ignore_index=train_dataset.output_pad_idx, reduction=\"sum\", weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T20:27:30.732070Z",
     "start_time": "2020-12-07T20:27:30.728165Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = {0: \"REFUTES\", 1: \"NOT ENOUGH INFO\", 2: \"SUPPORT\"}\n",
    "trainer = Trainer(mlp_model, optimizer, loss_fn, device, log_every_n=1)\n",
    "trainer.fit(\n",
    "    train_loader=mlp_train_loader,\n",
    "    valid_loader=mlp_test_loader,\n",
    "    labels=labels,\n",
    "    n_epochs=N_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
