{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:09:03.745024Z",
     "start_time": "2020-12-11T20:09:03.623235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:09:04.413978Z",
     "start_time": "2020-12-11T20:09:04.387943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/offendo/Documents/masters/nlp243/best-words/src\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%cd ../\";\n",
       "                var nbb_formatted_code = \"%cd ../\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:09:07.703137Z",
     "start_time": "2020-12-11T20:09:04.849635Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import data\\nfrom collections import Counter\\nfrom nli.retrieval import SentEmbed\\nimport nli.lstm as lstm\\nimport nli.mlp as mlp\\nfrom nli.trainer import Trainer\\nimport pandas as pd\\nimport numpy as np\\nimport torch\\nfrom torch.utils.data import DataLoader\\nimport torch.optim as optim\\nfrom sklearn.model_selection import train_test_split\\n\\n# torch.multiprocessing.set_start_method(\\\"spawn\\\", force=True)  # multiprocessing\\n# from sentence_transformers import SentenceTransformer, util\\n# from transformers import AutoTokenizer, AutoModelForMaskedLM\\n# import simpletransformers\\n# import spacy\\n# import pytextrank\";\n",
       "                var nbb_formatted_code = \"import data\\nfrom collections import Counter\\nfrom nli.retrieval import SentEmbed\\nimport nli.lstm as lstm\\nimport nli.mlp as mlp\\nfrom nli.trainer import Trainer\\nimport pandas as pd\\nimport numpy as np\\nimport torch\\nfrom torch.utils.data import DataLoader\\nimport torch.optim as optim\\nfrom sklearn.model_selection import train_test_split\\n\\n# torch.multiprocessing.set_start_method(\\\"spawn\\\", force=True)  # multiprocessing\\n# from sentence_transformers import SentenceTransformer, util\\n# from transformers import AutoTokenizer, AutoModelForMaskedLM\\n# import simpletransformers\\n# import spacy\\n# import pytextrank\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import data\n",
    "from collections import Counter\n",
    "from nli.retrieval import Embedder\n",
    "import nli.lstm as lstm\n",
    "import nli.mlp as mlp\n",
    "from nli.trainer import Trainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# torch.multiprocessing.set_start_method(\"spawn\", force=True)  # multiprocessing\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "# import simpletransformers\n",
    "# import spacy\n",
    "# import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:09:07.740603Z",
     "start_time": "2020-12-11T20:09:07.704876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# outdir = \\\"../data/clean/\\\"\\n# for file in tqdm(index.keys()):\\n#     wiki = data.get_wiki(file)\\n#     lines = wiki[\\\"lines\\\"].apply(lambda l: \\\"<SPLIT>\\\".join(data.clean_article(l)))\\n#     wiki[\\\"text\\\"] = lines\\n#     wiki = wiki.drop(\\\"lines\\\", axis=1).reset_index()\\n#     new_file = outdir + file.split(\\\"/\\\")[-1]\\n#     wiki.to_json(new_file, orient=\\\"records\\\", lines=True)\";\n",
       "                var nbb_formatted_code = \"# outdir = \\\"../data/clean/\\\"\\n# for file in tqdm(index.keys()):\\n#     wiki = data.get_wiki(file)\\n#     lines = wiki[\\\"lines\\\"].apply(lambda l: \\\"<SPLIT>\\\".join(data.clean_article(l)))\\n#     wiki[\\\"text\\\"] = lines\\n#     wiki = wiki.drop(\\\"lines\\\", axis=1).reset_index()\\n#     new_file = outdir + file.split(\\\"/\\\")[-1]\\n#     wiki.to_json(new_file, orient=\\\"records\\\", lines=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# outdir = \"../data/clean/\"\n",
    "# for file in tqdm(index.keys()):\n",
    "#     wiki = data.get_wiki(file)\n",
    "#     lines = wiki[\"lines\"].apply(lambda l: \"<SPLIT>\".join(data.clean_article(l)))\n",
    "#     wiki[\"text\"] = lines\n",
    "#     wiki = wiki.drop(\"lines\", axis=1).reset_index()\n",
    "#     new_file = outdir + file.split(\"/\")[-1]\n",
    "#     wiki.to_json(new_file, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:09:11.735035Z",
     "start_time": "2020-12-11T20:09:07.742750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"train = data.get_train(\\\"../data/train.jsonl\\\")\\ntrain = train.explode(\\\"evidence\\\").reset_index()\\ntrain, test = train_test_split(train)\";\n",
       "                var nbb_formatted_code = \"train = data.get_train(\\\"../data/train.jsonl\\\")\\ntrain = train.explode(\\\"evidence\\\").reset_index()\\ntrain, test = train_test_split(train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = data.get_train(\"../data/train.jsonl\")\n",
    "train = train.explode(\"evidence\").reset_index()\n",
    "train, test = train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:09:20.176963Z",
     "start_time": "2020-12-11T20:09:11.737596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"embedder = SentEmbed(\\\"distilroberta-base-msmarco-v2\\\")\";\n",
       "                var nbb_formatted_code = \"embedder = SentEmbed(\\\"distilroberta-base-msmarco-v2\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedder = SentEmbed(\"distilroberta-base-msmarco-v2\")\n",
    "embedder.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:23:46.134279Z",
     "start_time": "2020-12-11T20:23:45.609484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"train_dataset = data.SentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\ntest_dataset = data.SentenceDataset(test, embedder, \\\"../data/wiki.db\\\", 4)\";\n",
       "                var nbb_formatted_code = \"train_dataset = data.SentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\ntest_dataset = data.SentenceDataset(test, embedder, \\\"../data/wiki.db\\\", 4)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = data.SentenceDataset(train, embedder, \"../data/wiki.db\", 4)\n",
    "test_dataset = data.SentenceDataset(test, embedder, \"../data/wiki.db\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:23:46.704871Z",
     "start_time": "2020-12-11T20:23:46.657489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"train_loader = DataLoader(\\n    train_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=train_dataset.collate,\\n    num_workers=1,\\n    prefetch_factor=5,\\n)\\ntest_loader = DataLoader(\\n    test_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=test_dataset.collate,\\n    num_workers=1,  # doesn't work with more than 1 and a sqlite connection\\n    prefetch_factor=5,\\n)\";\n",
       "                var nbb_formatted_code = \"train_loader = DataLoader(\\n    train_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=train_dataset.collate,\\n    num_workers=1,\\n    prefetch_factor=5,\\n)\\ntest_loader = DataLoader(\\n    test_dataset,\\n    batch_size=64,\\n    shuffle=True,\\n    collate_fn=test_dataset.collate,\\n    num_workers=1,  # doesn't work with more than 1 and a sqlite connection\\n    prefetch_factor=5,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.collate,\n",
    "    num_workers=1,\n",
    "    prefetch_factor=5,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    collate_fn=test_dataset.collate,\n",
    "    num_workers=1,  # doesn't work with more than 1 and a sqlite connection\n",
    "    prefetch_factor=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:23:47.310521Z",
     "start_time": "2020-12-11T20:23:47.274473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIM = 100\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nN_LAYERS = 2\\nDROPOUT = 1e-1\\nBIDIRECTIONAL = True\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-3\\nLR_DECAY = 1e-3\";\n",
       "                var nbb_formatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIM = 100\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nN_LAYERS = 2\\nDROPOUT = 1e-1\\nBIDIRECTIONAL = True\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-3\\nLR_DECAY = 1e-3\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Model params\n",
    "EMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\n",
    "HIDDEN_DIM = 100\n",
    "OUTPUT_DIM = 3  # refute, not enough info, support\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 1e-1\n",
    "BIDIRECTIONAL = True\n",
    "# Loss fn params\n",
    "WEIGHT_DECAY = 1e-4\n",
    "N_EPOCHS = 3\n",
    "LR = 1e-3\n",
    "LR_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:23:48.048739Z",
     "start_time": "2020-12-11T20:23:47.953090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"model = lstm.LSTMClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dim=HIDDEN_DIM,\\n    output_dim=OUTPUT_DIM,\\n    n_layers=N_LAYERS,\\n    dropout=DROPOUT,\\n    bidirectional=BIDIRECTIONAL,\\n    pad_idx=train_dataset.input_pad_idx,\\n)\\nmodel.to(device)\\n# state_dict = torch.load(\\\"../models/bilstm-nli-model-2.pt\\\")\\n# model.load_state_dict(state_dict)\\noptimizer = optim.Adam(model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx,\\n    reduction=\\\"sum\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"model = lstm.LSTMClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dim=HIDDEN_DIM,\\n    output_dim=OUTPUT_DIM,\\n    n_layers=N_LAYERS,\\n    dropout=DROPOUT,\\n    bidirectional=BIDIRECTIONAL,\\n    pad_idx=train_dataset.input_pad_idx,\\n)\\nmodel.to(device)\\n# state_dict = torch.load(\\\"../models/bilstm-nli-model-2.pt\\\")\\n# model.load_state_dict(state_dict)\\noptimizer = optim.Adam(model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx,\\n    reduction=\\\"sum\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lstm.LSTMClassifier(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    pad_idx=train_dataset.input_pad_idx,\n",
    ")\n",
    "model.to(device)\n",
    "# state_dict = torch.load(\"../models/bilstm-nli-model-2.pt\")\n",
    "# model.load_state_dict(state_dict)\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(\n",
    "    ignore_index=train_dataset.output_pad_idx,\n",
    "    reduction=\"sum\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:23:48.592075Z",
     "start_time": "2020-12-11T20:23:48.545951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"trainer = Trainer(model, optimizer, loss_fn, device, log_every_n=1)\\nlabels = {0: \\\"REFUTES\\\", 1: \\\"NOT ENOUGH INFO\\\", 2: \\\"SUPPORT\\\"}\";\n",
       "                var nbb_formatted_code = \"trainer = Trainer(model, optimizer, loss_fn, device, log_every_n=1)\\nlabels = {0: \\\"REFUTES\\\", 1: \\\"NOT ENOUGH INFO\\\", 2: \\\"SUPPORT\\\"}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, loss_fn, device, log_every_n=1)\n",
    "labels = {0: \"REFUTES\", 1: \"NOT ENOUGH INFO\", 2: \"SUPPORT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T20:25:10.071120Z",
     "start_time": "2020-12-11T20:23:49.092470Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LSTMClassifier(\n",
      "  (lstm): LSTM(1537, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "loss_fn: CrossEntropyLoss()\n",
      "Epoch number 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-abd3ed0f9d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/masters/nlp243/best-words/src/nli/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, valid_loader, labels, n_epochs)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch number {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;31m# Record the loss from both training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_loss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             valid_loss_hist, valid_running_loss_hist = self.evaluate(\n",
      "\u001b[0;32m~/Documents/masters/nlp243/best-words/src/nli/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mrunning_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/masters/nlp243/best-words/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/masters/nlp243/best-words/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/masters/nlp243/best-words/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"model.share_memory()\\ntrainer.fit(\\n    train_loader=train_loader,\\n    valid_loader=test_loader,\\n    labels=labels,\\n    n_epochs=N_EPOCHS,\\n)\";\n",
       "                var nbb_formatted_code = \"model.share_memory()\\ntrainer.fit(\\n    train_loader=train_loader,\\n    valid_loader=test_loader,\\n    labels=labels,\\n    n_epochs=N_EPOCHS,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.share_memory()\n",
    "trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=test_loader,\n",
    "    labels=labels,\n",
    "    n_epochs=N_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T17:58:52.833082Z",
     "start_time": "2020-12-07T17:58:52.802263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 152;\n",
       "                var nbb_unformatted_code = \"# torch.save(model.state_dict(), \\\"../models/bilstm-nli-model-3.pt\\\")\";\n",
       "                var nbb_formatted_code = \"# torch.save(model.state_dict(), \\\"../models/bilstm-nli-model-3.pt\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"../models/bilstm-nli-model-3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:22:42.873737Z",
     "start_time": "2020-12-07T21:22:42.809210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Small test dataset/loader\\nsmall_test_dataset = data.SentenceDataset(test[:1000], embedder, \\\"../data/wiki.db\\\", 4)\\nsmall_test_loader = DataLoader(\\n    small_test_dataset,\\n    batch_size=4,\\n    shuffle=False,\\n    collate_fn=test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_formatted_code = \"# Small test dataset/loader\\nsmall_test_dataset = data.SentenceDataset(test[:1000], embedder, \\\"../data/wiki.db\\\", 4)\\nsmall_test_loader = DataLoader(\\n    small_test_dataset,\\n    batch_size=4,\\n    shuffle=False,\\n    collate_fn=test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Small test dataset/loader\n",
    "small_test_dataset = data.SentenceDataset(test[:1000], embedder, \"../data/wiki.db\", 4)\n",
    "small_test_loader = DataLoader(\n",
    "    small_test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=test_dataset.collate,\n",
    "    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:24:06.497117Z",
     "start_time": "2020-12-07T21:22:43.849478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [01:22<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 11.962440080420919\n",
      "Classification report after epoch:\n",
      "Evidence accuracy: 0.320139697322468\n",
      "Number correct: 275 out of 859\n",
      "Fever score: 0.36321303841676367\n",
      "Number right: 312 out of 859\n",
      "Label accuracy: 0.6507566938300349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"loss, running_loss = trainer.evaluate(small_test_loader, labels)\";\n",
       "                var nbb_formatted_code = \"loss, running_loss = trainer.evaluate(small_test_loader, labels)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, running_loss = trainer.evaluate(small_test_loader, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:56:27.464560Z",
     "start_time": "2020-12-07T21:56:27.427836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"claim = \\\"George Lucas and Mark Hamill have worked together\\\"\\na = \\\"Luke Skywalker is a protagonist in Star Wars\\\"\\nb = \\\"George Lucas directs Star Wars\\\"\\nc = \\\"Mark Hamill plays Luke Skywalker\\\"\\nd = b + \\\" and \\\" + c\\ne = \\\"Mark Hamill and George Lucas were part of Star Wars\\\"\";\n",
       "                var nbb_formatted_code = \"claim = \\\"George Lucas and Mark Hamill have worked together\\\"\\na = \\\"Luke Skywalker is a protagonist in Star Wars\\\"\\nb = \\\"George Lucas directs Star Wars\\\"\\nc = \\\"Mark Hamill plays Luke Skywalker\\\"\\nd = b + \\\" and \\\" + c\\ne = \\\"Mark Hamill and George Lucas were part of Star Wars\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "claim = \"George Lucas and Mark Hamill have worked together\"\n",
    "a = \"Luke Skywalker is a protagonist in Star Wars\"\n",
    "b = \"George Lucas directs Star Wars\"\n",
    "c = \"Mark Hamill plays Luke Skywalker\"\n",
    "d = b + \" and \" + c\n",
    "e = \"Mark Hamill and George Lucas were part of Star Wars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T21:56:29.485180Z",
     "start_time": "2020-12-07T21:56:29.423480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1483, 0.3690, 0.4195, 0.4155, 0.7016]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"embedder.compare(claim, [a, b, c, d, e])\";\n",
       "                var nbb_formatted_code = \"embedder.compare(claim, [a, b, c, d, e])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedder.compare(claim, [a, b, c, d, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:48.208576Z",
     "start_time": "2020-12-07T16:04:47.815292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 117;\n",
       "                var nbb_unformatted_code = \"mlp_train_dataset = data.MLPSentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\nmlp_test_dataset = data.MLPSentenceDataset(test[:100], embedder, \\\"../data/wiki.db\\\", 4)\\n\\nmlp_train_loader = DataLoader(\\n    mlp_train_dataset,\\n    batch_size=512,\\n    shuffle=True,\\n    collate_fn=mlp_train_dataset.collate,\\n    num_workers=0,\\n)\\nmlp_test_loader = DataLoader(\\n    mlp_test_dataset,\\n    batch_size=20,\\n    shuffle=False,\\n    collate_fn=mlp_test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_formatted_code = \"mlp_train_dataset = data.MLPSentenceDataset(train, embedder, \\\"../data/wiki.db\\\", 4)\\nmlp_test_dataset = data.MLPSentenceDataset(test[:100], embedder, \\\"../data/wiki.db\\\", 4)\\n\\nmlp_train_loader = DataLoader(\\n    mlp_train_dataset,\\n    batch_size=512,\\n    shuffle=True,\\n    collate_fn=mlp_train_dataset.collate,\\n    num_workers=0,\\n)\\nmlp_test_loader = DataLoader(\\n    mlp_test_dataset,\\n    batch_size=20,\\n    shuffle=False,\\n    collate_fn=mlp_test_dataset.collate,\\n    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_train_dataset = data.MLPSentenceDataset(train, embedder, \"../data/wiki.db\", 4)\n",
    "mlp_test_dataset = data.MLPSentenceDataset(test[:100], embedder, \"../data/wiki.db\", 4)\n",
    "\n",
    "mlp_train_loader = DataLoader(\n",
    "    mlp_train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    collate_fn=mlp_train_dataset.collate,\n",
    "    num_workers=0,\n",
    ")\n",
    "mlp_test_loader = DataLoader(\n",
    "    mlp_test_dataset,\n",
    "    batch_size=20,\n",
    "    shuffle=False,\n",
    "    collate_fn=mlp_test_dataset.collate,\n",
    "    num_workers=0,  # doesn't work with more than 1 and a sqlite connection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:50.501493Z",
     "start_time": "2020-12-07T16:04:48.245013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 118;\n",
       "                var nbb_unformatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIMS = [300, 50]\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nDROPOUT = 1e-1\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-2\\nLR_DECAY = 1e-3\\n# Class weights\\nlens = train[\\\"evidence\\\"].apply(len)\\nlabs = train[\\\"label\\\"].apply(lambda x: [x])\\n# Assuming we have 15 selected sentences per claim (and 100% recall)\\n# We would have X of them be the correct label (number of evidence in the evidence column)\\n# and 15 - X would be NEI. This is a way to adjust the class weights to account for that\\nnei = train[\\\"label\\\"].apply(lambda x: [1])\\nfrequencies = ((15 - lens) * nei + (labs * lens)).explode().value_counts().sort_index()\\nclass_weights = 1 + torch.softmax(-torch.log2(torch.Tensor(frequencies)), dim=0).to(\\n    device\\n)\";\n",
       "                var nbb_formatted_code = \"# General\\ndevice = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n# Model params\\nEMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\\nHIDDEN_DIMS = [300, 50]\\nOUTPUT_DIM = 3  # refute, not enough info, support\\nDROPOUT = 1e-1\\n# Loss fn params\\nWEIGHT_DECAY = 1e-4\\nN_EPOCHS = 3\\nLR = 1e-2\\nLR_DECAY = 1e-3\\n# Class weights\\nlens = train[\\\"evidence\\\"].apply(len)\\nlabs = train[\\\"label\\\"].apply(lambda x: [x])\\n# Assuming we have 15 selected sentences per claim (and 100% recall)\\n# We would have X of them be the correct label (number of evidence in the evidence column)\\n# and 15 - X would be NEI. This is a way to adjust the class weights to account for that\\nnei = train[\\\"label\\\"].apply(lambda x: [1])\\nfrequencies = ((15 - lens) * nei + (labs * lens)).explode().value_counts().sort_index()\\nclass_weights = 1 + torch.softmax(-torch.log2(torch.Tensor(frequencies)), dim=0).to(\\n    device\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Model params\n",
    "EMBEDDING_DIM = embedder.model.get_sentence_embedding_dimension()\n",
    "HIDDEN_DIMS = [300, 50]\n",
    "OUTPUT_DIM = 3  # refute, not enough info, support\n",
    "DROPOUT = 1e-1\n",
    "# Loss fn params\n",
    "WEIGHT_DECAY = 1e-4\n",
    "N_EPOCHS = 3\n",
    "LR = 1e-2\n",
    "LR_DECAY = 1e-3\n",
    "# Class weights\n",
    "lens = train[\"evidence\"].apply(len)\n",
    "labs = train[\"label\"].apply(lambda x: [x])\n",
    "# Assuming we have 15 selected sentences per claim (and 100% recall)\n",
    "# We would have X of them be the correct label (number of evidence in the evidence column)\n",
    "# and 15 - X would be NEI. This is a way to adjust the class weights to account for that\n",
    "nei = train[\"label\"].apply(lambda x: [1])\n",
    "frequencies = ((15 - lens) * nei + (labs * lens)).explode().value_counts().sort_index()\n",
    "class_weights = 1 + torch.softmax(-torch.log2(torch.Tensor(frequencies)), dim=0).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:50.544590Z",
     "start_time": "2020-12-07T16:04:50.502970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (fc1): Linear(in_features=1537, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 119;\n",
       "                var nbb_unformatted_code = \"mlp_model = mlp.MLPClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dims=HIDDEN_DIMS,\\n    output_dim=OUTPUT_DIM,\\n    dropout=DROPOUT,\\n    pad_idx=mlp_train_dataset.input_pad_idx,\\n)\\nmlp_model.to(device)\";\n",
       "                var nbb_formatted_code = \"mlp_model = mlp.MLPClassifier(\\n    embedding_dim=EMBEDDING_DIM,\\n    hidden_dims=HIDDEN_DIMS,\\n    output_dim=OUTPUT_DIM,\\n    dropout=DROPOUT,\\n    pad_idx=mlp_train_dataset.input_pad_idx,\\n)\\nmlp_model.to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_model = mlp.MLPClassifier(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dims=HIDDEN_DIMS,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=mlp_train_dataset.input_pad_idx,\n",
    ")\n",
    "mlp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T16:04:50.605099Z",
     "start_time": "2020-12-07T16:04:50.547357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 120;\n",
       "                var nbb_unformatted_code = \"optimizer = optim.Adam(mlp_model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx, reduction=\\\"sum\\\", weight=class_weights\\n)\";\n",
       "                var nbb_formatted_code = \"optimizer = optim.Adam(mlp_model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\\nloss_fn = torch.nn.CrossEntropyLoss(\\n    ignore_index=train_dataset.output_pad_idx, reduction=\\\"sum\\\", weight=class_weights\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optim.Adam(mlp_model.parameters(), weight_decay=WEIGHT_DECAY, lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(\n",
    "    ignore_index=train_dataset.output_pad_idx, reduction=\"sum\", weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T20:27:30.732070Z",
     "start_time": "2020-12-07T20:27:30.728165Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = {0: \"REFUTES\", 1: \"NOT ENOUGH INFO\", 2: \"SUPPORT\"}\n",
    "trainer = Trainer(mlp_model, optimizer, loss_fn, device, log_every_n=1)\n",
    "trainer.fit(\n",
    "    train_loader=mlp_train_loader,\n",
    "    valid_loader=mlp_test_loader,\n",
    "    labels=labels,\n",
    "    n_epochs=N_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
